{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     10\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Adjust the path as needed\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspacy_visualizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpacyLabelVisualizer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# TODO: there must be some cleaner way use local packages with poetry, but lets use this quick hack for now...\n",
    "import sys\n",
    "sys.path.append('../../')  # Adjust the path as needed\n",
    "from utils.spacy_visualizer import SpacyLabelVisualizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurate OpenAI Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "OPENAI_SECRET_KEY = os.getenv('OPENAI_SECRET_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_SECRET_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data.xlsx').iloc[1:99,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read txt file. Do not use with open\n",
    "prompt1 = open('prompt_1.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict / Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticRoleLabeler:\n",
    "  def __init__(self, prompt: str):\n",
    "    self._seed = 42 # ensure reproducable results\n",
    "    self._temperature = 0.0 # ensure deterministic results\n",
    "    self._client = OpenAI() \n",
    "    self._model = \"gpt-3.5-turbo-1106\" \n",
    "    # self._model=\"gpt-4-1106-preview\", # this is expensive\n",
    "    self.system_prompt = prompt   \n",
    "    \n",
    "    \n",
    "  # MARK: - Public Methods\n",
    "  def label(self, sentence) -> [str]:\n",
    "    response = self._computeReponse(sentence)\n",
    "    message = self._extract_message_from_response(response)\n",
    "    string_valued_labels = self._extract_final_line(message)\n",
    "    # string_valued_labels = self._extract_message_from_response(message)\n",
    "    labels = self._convert_string_typed_labels_to_proper_List(string_valued_labels)\n",
    "    return labels\n",
    "        \n",
    "  # MARK: - Private Methods\n",
    "  def _computeReponse(self, sentence):\n",
    "     response = self._client.chat.completions.create(\n",
    "      seed=self._seed, \n",
    "      temperature=self._temperature, \n",
    "      model=self._model,\n",
    "      # response_format={ \"type\": \"json_object\" },\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "        {\"role\": \"user\", \"content\": sentence},\n",
    "      ],\n",
    "      # stream=True,\n",
    "    )\n",
    "     return response\n",
    "  \n",
    "     \n",
    "  def _extract_message_from_response(self, response) -> str:\n",
    "    return response.choices[0].message.content\n",
    "  \n",
    "  def _extract_final_line(self, message: str) -> str:\n",
    "    message.split(\"```\\n\")[-1]\n",
    "    # remove trailing \\n```\n",
    "    message = message.split(\"```\\n\")[-1].replace(\"\\n```\", \"\")\n",
    "    return message\n",
    "    \n",
    "    \n",
    "  # deprecated; was used for sentence level semantic role labeling\n",
    "  def _convert_string_typed_labels_to_proper_List(self, message: str) -> list:\n",
    "    try:\n",
    "      result = ast.literal_eval(message)\n",
    "    except:\n",
    "      print(\"Error: could not convert string to list\")\n",
    "      print(f\"Received message: \\n\\n {message}\")\n",
    "      result = []\n",
    "    return result\n",
    "    # return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labeler = SemanticRoleLabeler(prompt=prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 4th column\n",
    "tokenized_sentences = df[\"Unnamed: 3\"]\n",
    "labels = df[\"Unnamed: 4\"]\n",
    "\n",
    "sentence = ast.literal_eval(tokenized_sentences[10])\n",
    "label = ast.literal_eval(labels[10])\n",
    "print(sentence)\n",
    "print(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_labels = Labeler.label(str(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = SpacyLabelVisualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.display(sentence, sentence_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
